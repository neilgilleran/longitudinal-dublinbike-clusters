{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cluster.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OGkBefXU5nBX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZBnBx7np5n1i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-I1edvS8S1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P56eVdBs8naE",
        "colab_type": "code",
        "outputId": "737e0345-b184-45cd-e73e-9996b5f765f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1vk4HijV9ZAR",
        "colab_type": "code",
        "outputId": "dbf5d83e-763b-4ebb-df2d-0b2fb2539387",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd drive\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i4FMnVmLpPS7",
        "colab_type": "code",
        "outputId": "9ce0fc55-407b-410a-9b73-13a3b692c07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd 'My Drive'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EqVNm1wZpQpT",
        "colab_type": "code",
        "outputId": "7aa8e56c-038f-47c0-b64d-a57f22636c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cd Colab\\ Notebooks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Gp1N6KIu_pq2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('2018-01-01-with_kmlshapes.csv' , index_col='timestamp', parse_dates=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wwl34y0X_py_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xICs0iFr5n_V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df.reset_index()\n",
        "df = df.sort_values(by=['station_id','timestamp'])\n",
        "df['bike_pull'] = df['bikes'].shift(-1).fillna(0).astype(int)\n",
        "df = df.sort_values(by=['timestamp','station_id'])\n",
        "df = df.set_index('timestamp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-VF_h31W9ijd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stations = pd.read_csv('stations-clusters-input.csv', index_col='station_id')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cEOtBFZh816V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import classification_report, confusion_matrix  \n",
        "from sklearn.preprocessing import StandardScaler  \n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRwtclxh-erk",
        "colab_type": "code",
        "outputId": "2dfa6872-6f78-4fb5-89db-91cfc3bc61fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "cell_type": "code",
      "source": [
        "df[df['cluster']==1].info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2714198 entries, 2018-01-01 00:00:02 to 2018-06-28 16:46:02\n",
            "Data columns (total 9 columns):\n",
            "station_id     int64\n",
            "bikes          int64\n",
            "spaces         int64\n",
            "total_docks    int64\n",
            "norm           float64\n",
            "time           float64\n",
            "day_of_week    int64\n",
            "cluster        int64\n",
            "bike_pull      int64\n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 207.1 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FDisinli9CLA",
        "colab_type": "code",
        "outputId": "3c8866db-3e92-40bd-fa3d-2e7d08587c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "cell_type": "code",
      "source": [
        "#station_runner = df['station_id'].value_counts().count()\n",
        "#This will run for all 7 clusters\n",
        "station_runner = 8\n",
        "print(station_runner)\n",
        "data=[] \n",
        "stuff_heads = ['station_id', 'station_name','mse']\n",
        "print(\"Model per station\\n\\n\",station_runner)\n",
        "\n",
        "\n",
        "rfr_mae=[]\n",
        "clf_mae=[]\n",
        "nn_mae=[]\n",
        "stashions=[]\n",
        "\n",
        "for i in range(1,station_runner):\n",
        "        \n",
        "    print(\"i: \",i)\n",
        "    try:\n",
        "        station_x = df[df['cluster']==i]\n",
        "        print(station_x.info())\n",
        "\n",
        "        X = station_x.drop('bike_pull', axis=1)\n",
        "        y = station_x['bike_pull']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "          \n",
        "        scaler = StandardScaler()  \n",
        "        scaler.fit(X_train)\n",
        "        print(\"Scaler\")\n",
        "        X_train = scaler.transform(X_train)  \n",
        "        X_test = scaler.transform(X_test) \n",
        "        \n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf_model = clf.fit(X_train, y_train)\n",
        "        print(\"clf\")        \n",
        "        \n",
        "        mlp = MLPRegressor(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
        "        mlp.fit(X_train, y_train.values.ravel())  \n",
        "        print(\"mlp\")\n",
        "        \n",
        "        rfr = RandomForestRegressor(n_estimators=50, random_state=0, n_jobs=-1)\n",
        "        rfr_model = rfr.fit(X_train, y_train)\n",
        "        print(\"rfr\")        \n",
        "        \n",
        "        clf_predictions = clf.predict(X_test)\n",
        "        rfr_predictions = rfr.predict(X_test)\n",
        "        mlp_predictions = mlp.predict(X_test)        \n",
        "        \n",
        "        clf_errors = abs(clf_predictions - y_test)\n",
        "        rfr_errors = abs(rfr_predictions - y_test)        \n",
        "        mlp_errors = abs(mlp_predictions - y_test)\n",
        "        \n",
        "        print('Station is: ', stations.Name[stations.index==i].to_string())\n",
        "        print('clf Mean Absolute Error:', round(np.mean(clf_errors), 2), 'degrees.')\n",
        "        print('rfr Mean Absolute Error:', round(np.mean(rfr_errors), 2), 'degrees.')     \n",
        "        print('mlp Mean Absolute Error:', round(np.mean(mlp_errors), 2), 'degrees.\\n')\n",
        "        \n",
        "        stashions.append(i)\n",
        "          \n",
        "        x = round(np.mean(clf_errors), 2)\n",
        "        y = round(np.mean(rfr_errors), 2)        \n",
        "        z = round(np.mean(mlp_errors), 2)\n",
        "        \n",
        "        clf_mae.append(x)\n",
        "        rfr_mae.append(y)\n",
        "        nn_mae.append(z)\n",
        "        \n",
        "        stashions.append(i)\n",
        "        \n",
        "    except:\n",
        "        print(\"Problem with: \", i)\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "Model per station\n",
            "\n",
            " 2\n",
            "i:  1\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2714198 entries, 2018-01-01 00:00:02 to 2018-06-28 16:46:02\n",
            "Data columns (total 9 columns):\n",
            "station_id     int64\n",
            "bikes          int64\n",
            "spaces         int64\n",
            "total_docks    int64\n",
            "norm           float64\n",
            "time           float64\n",
            "day_of_week    int64\n",
            "cluster        int64\n",
            "bike_pull      int64\n",
            "dtypes: float64(2), int64(7)\n",
            "memory usage: 207.1 MB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "  return self.partial_fit(X, y)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Scaler\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PWZr6NoU9QWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#station_runner = df['station_id'].value_counts().count()\n",
        "#This will run for all the datafame (this will take yonks)\n",
        "station_runner = 1\n",
        "print(station_runner)\n",
        "data=[] \n",
        "stuff_heads = ['station_id', 'station_name','mse']\n",
        "print(\"Model per station\\n\\n\",station_runner)\n",
        "\n",
        "\n",
        "rfr_mae=[]\n",
        "clf_mae=[]\n",
        "nn_mae=[]\n",
        "stashions=[]\n",
        "\n",
        "for i in range(1,station_runner):\n",
        "        \n",
        "    print(\"i: \",i)\n",
        "    try:\n",
        "        station_x = df\n",
        "        print(station_x.info())\n",
        "\n",
        "        X = station_x.drop('bike_pull', axis=1)\n",
        "        y = station_x['bike_pull']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "          \n",
        "        scaler = StandardScaler()  \n",
        "        scaler.fit(X_train)\n",
        "        print(\"Scaler\")\n",
        "        X_train = scaler.transform(X_train)  \n",
        "        X_test = scaler.transform(X_test) \n",
        "        \n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf_model = clf.fit(X_train, y_train)\n",
        "        print(\"clf\")        \n",
        "        \n",
        "        mlp = MLPRegressor(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
        "        mlp.fit(X_train, y_train.values.ravel())  \n",
        "        print(\"mlp\")\n",
        "        \n",
        "        rfr = RandomForestRegressor(n_estimators=50, random_state=0, n_jobs=-1)\n",
        "        rfr_model = rfr.fit(X_train, y_train)\n",
        "        print(\"rfr\")        \n",
        "        \n",
        "        clf_predictions = clf.predict(X_test)\n",
        "        rfr_predictions = rfr.predict(X_test)\n",
        "        mlp_predictions = mlp.predict(X_test)        \n",
        "        \n",
        "        clf_errors = abs(clf_predictions - y_test)\n",
        "        rfr_errors = abs(rfr_predictions - y_test)        \n",
        "        mlp_errors = abs(mlp_predictions - y_test)\n",
        "        \n",
        "        print('Station is: ', stations.Name[stations.index==i].to_string())\n",
        "        print('clf Mean Absolute Error:', round(np.mean(clf_errors), 2), 'degrees.')\n",
        "        print('rfr Mean Absolute Error:', round(np.mean(rfr_errors), 2), 'degrees.')     \n",
        "        print('mlp Mean Absolute Error:', round(np.mean(mlp_errors), 2), 'degrees.\\n')\n",
        "        \n",
        "        stashions.append(i)\n",
        "          \n",
        "        x = round(np.mean(clf_errors), 2)\n",
        "        y = round(np.mean(rfr_errors), 2)        \n",
        "        z = round(np.mean(mlp_errors), 2)\n",
        "        \n",
        "        clf_mae.append(x)\n",
        "        rfr_mae.append(y)\n",
        "        nn_mae.append(z)\n",
        "        \n",
        "        stashions.append(i)\n",
        "        \n",
        "    except:\n",
        "        print(\"Problem with: \", i)\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1IfJRsDMIMIk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#station_runner = df['station_id'].value_counts().count()\n",
        "#This will run for each station\n",
        "station_runner = 120\n",
        "print(station_runner)\n",
        "data=[] \n",
        "stuff_heads = ['station_id', 'station_name','mse']\n",
        "print(\"Model per station\\n\\n\",station_runner)\n",
        "\n",
        "\n",
        "rfr_mae=[]\n",
        "clf_mae=[]\n",
        "nn_mae=[]\n",
        "stashions=[]\n",
        "\n",
        "for i in range(1,station_runner):\n",
        "        \n",
        "    print(\"i: \",i)\n",
        "    try:\n",
        "        station_x = df2[df2['station_id']==i]\n",
        "        print(station_x.info())\n",
        "\n",
        "        X = station_x.drop('bike_pull', axis=1)\n",
        "        y = station_x['bike_pull']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)\n",
        "          \n",
        "        scaler = StandardScaler()  \n",
        "        scaler.fit(X_train)\n",
        "        print(\"Scaler\")\n",
        "        X_train = scaler.transform(X_train)  \n",
        "        X_test = scaler.transform(X_test) \n",
        "        \n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf_model = clf.fit(X_train, y_train)\n",
        "        print(\"clf\")        \n",
        "        \n",
        "        mlp = MLPRegressor(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
        "        mlp.fit(X_train, y_train.values.ravel())  \n",
        "        print(\"mlp\")\n",
        "        \n",
        "        rfr = RandomForestRegressor(n_estimators=50, random_state=0, n_jobs=-1)\n",
        "        rfr_model = rfr.fit(X_train, y_train)\n",
        "        print(\"rfr\")        \n",
        "        \n",
        "        clf_predictions = clf.predict(X_test)\n",
        "        rfr_predictions = rfr.predict(X_test)\n",
        "        mlp_predictions = mlp.predict(X_test)        \n",
        "        \n",
        "        clf_errors = abs(clf_predictions - y_test)\n",
        "        rfr_errors = abs(rfr_predictions - y_test)        \n",
        "        mlp_errors = abs(mlp_predictions - y_test)\n",
        "        \n",
        "        print('Station is: ', stations.Name[stations.index==i].to_string())\n",
        "        print('clf Mean Absolute Error:', round(np.mean(clf_errors), 2), 'degrees.')\n",
        "        print('rfr Mean Absolute Error:', round(np.mean(rfr_errors), 2), 'degrees.')     \n",
        "        print('mlp Mean Absolute Error:', round(np.mean(mlp_errors), 2), 'degrees.\\n')\n",
        "        \n",
        "        stashions.append(i)\n",
        "          \n",
        "        x = round(np.mean(clf_errors), 2)\n",
        "        y = round(np.mean(rfr_errors), 2)        \n",
        "        z = round(np.mean(mlp_errors), 2)\n",
        "        \n",
        "        clf_mae.append(x)\n",
        "        rfr_mae.append(y)\n",
        "        nn_mae.append(z)\n",
        "        \n",
        "        stashions.append(i)\n",
        "        \n",
        "    except:\n",
        "        print(\"Problem with: \", i)\n",
        "        pass\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}